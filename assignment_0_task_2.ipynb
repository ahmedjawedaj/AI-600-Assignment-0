{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Assignment 0 - Task 2: Naive Bayes Classifier\n",
                "\n",
                "## Problem Statement\n",
                "Predict Heart Disease (`target`) using patient attributes (`age`, `sex`, `chol`, etc).\n",
                "We will build the **Naive Bayes** algorithm from scratch, demonstrating the logic step-by-step.\n",
                "\n",
                "## Approach: Incremental Building\n",
                "1.  **Data Preparation**: We will process the data one variable at a time.\n",
                "2.  **The Math**: We will define independent functions for the core formulas (`Prior`, `Likelihood`).\n",
                "3.  **The Assembly**: We will combine these functions into a `CustomNaiveBayes` class.\n",
                "4.  **Evaluation**: We will compare our results with `sklearn`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Preparation\n",
                "First, we load the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('heart-dataset.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's inspect the raw data to identify text columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1 Encoding Target\n",
                "The `target` column contains strings. Let's check the unique values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['target'].unique()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will convert 'No Disease' to 0, and any other value (Disease) to 1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['target'] = df['target'].apply(lambda x: 0 if 'No Disease' in str(x) else 1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's verify the counts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['target'].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2 Encoding Categorical Features\n",
                "The `sex` column is also categorical (`Male`, `Female`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['sex'].unique()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We map `Male` to 1 and `Female` to 0."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['sex'] = df['sex'].map({'Male': 1, 'Female': 0})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For this initial implementation, we will select only the numeric features to ensure our probability functions work smoothly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df.select_dtypes(include=[np.number]).drop(columns=['target'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's verify which features we selected."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X.columns.tolist()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Component Implementation\n",
                "We will now implement the core mathematical components of Naive Bayes as independent functions."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 The Prior\n",
                "The prior probability $P(C)$ represents the frequency of a class in the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_prior(df, target_col, class_val):\n",
                "    total_samples = len(df)\n",
                "    class_samples = len(df[df[target_col] == class_val])\n",
                "    return class_samples / total_samples"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Test:** Check the probability of having the disease in our dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prior_disease = get_prior(df, 'target', 1)\n",
                "print(f\"Prior Probability of Disease: {prior_disease:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Gaussian Likelihood\n",
                "For continuous features (like `Age`), we assume a Normal Distribution. The probability density function is:\n",
                "$$ P(x|C) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def gaussian_pdf(x, mean, var):\n",
                "    epsilon = 1e-9 # Smoothing to avoid division by zero\n",
                "    coefficient = 1 / np.sqrt(2 * np.pi * (var + epsilon))\n",
                "    exponent = np.exp(-((x - mean)**2) / (2 * (var + epsilon)))\n",
                "    return coefficient * exponent"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Test:** Let's verify this with a simple example. If the mean age of sick patients is 55, a patient aged 60 should have a higher probability than a patient aged 20."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_mean = 55\n",
                "test_var = 100\n",
                "\n",
                "prob_60 = gaussian_pdf(60, test_mean, test_var)\n",
                "prob_20 = gaussian_pdf(20, test_mean, test_var)\n",
                "\n",
                "print(f\"Likelihood of Age 60: {prob_60:.5f}\")\n",
                "print(f\"Likelihood of Age 20: {prob_20:.5f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Class Assembly\n",
                "We will now organize these components into a standardized Python class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CustomNaiveBayes:\n",
                "    def fit(self, X, y):\n",
                "        # Store unique classes (0, 1)\n",
                "        self.classes = np.unique(y)\n",
                "        n_classes = len(self.classes)\n",
                "        n_features = X.shape[1]\n",
                "        \n",
                "        # Initialize arrays to store Mean, Variance, and Priors for each class\n",
                "        self.means = np.zeros((n_classes, n_features))\n",
                "        self.vars = np.zeros((n_classes, n_features))\n",
                "        self.priors = np.zeros(n_classes)\n",
                "        \n",
                "        for idx, c in enumerate(self.classes):\n",
                "            # Subset data for class `c`\n",
                "            X_c = X[y == c]\n",
                "            \n",
                "            # Calculate statistics\n",
                "            self.means[idx, :] = X_c.mean(axis=0)\n",
                "            self.vars[idx, :] = X_c.var(axis=0)\n",
                "            self.priors[idx] = X_c.shape[0] / len(X)\n",
                "            \n",
                "    def predict(self, X):\n",
                "        # Predict for every row in X\n",
                "        y_pred = [self._predict_single(x) for x in X.values]\n",
                "        return np.array(y_pred)\n",
                "    \n",
                "    def _predict_single(self, x):\n",
                "        posteriors = []\n",
                "        \n",
                "        for idx, c in enumerate(self.classes):\n",
                "            # 1. Start with Log Prior\n",
                "            prior = np.log(self.priors[idx])\n",
                "            \n",
                "            # 2. Calculate Likelihood for all features using Gaussian PDF\n",
                "            class_pdf = gaussian_pdf(x, self.means[idx], self.vars[idx])\n",
                "            \n",
                "            # 3. Sum Log Likelihoods (Log Sum is equivalent to Product in raw probability)\n",
                "            posterior = prior + np.sum(np.log(class_pdf))\n",
                "            posteriors.append(posterior)\n",
                "            \n",
                "        # Return the class with the highest posterior probability\n",
                "        return self.classes[np.argmax(posteriors)]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training and Evaluation\n",
                "We will now train the model on the full dataset and evaluate it."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 Splitting Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "y = df['target']\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Training Custom Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = CustomNaiveBayes()\n",
                "model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 Prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions = model.predict(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.4 Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "\n",
                "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
                "print(classification_report(y_test, predictions))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Benchmarking\n",
                "Verifying our implementation against `sklearn`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.naive_bayes import GaussianNB\n",
                "\n",
                "sk_model = GaussianNB()\n",
                "sk_model.fit(X_train, y_train)\n",
                "sk_preds = sk_model.predict(X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Sklearn Accuracy:\", accuracy_score(y_test, sk_preds))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}